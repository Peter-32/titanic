{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/peterjmyers/Documents/Python_Modules\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "import numpy as np\n",
    "from file_util.file_util import *\n",
    "from sql_util.sql_util import *\n",
    "\n",
    "df = pd.read_csv('./train.csv')\n",
    "\n",
    "def add_has_letter_in_ticket_to_df():\n",
    "    has_letter_in_ticket = []\n",
    "    for index, row in df.iterrows():\n",
    "        variable = re.match('.*([A-Za-z]).*', str(row['Ticket']))\n",
    "        if variable == None:\n",
    "            has_letter_in_ticket.append(0)\n",
    "        else:\n",
    "            has_letter_in_ticket.append(1)\n",
    "    df['has_letter_in_ticket'] = has_letter_in_ticket\n",
    "    \n",
    "add_has_letter_in_ticket_to_df()    \n",
    "clean_df = get_df_from_local_query('./sql/clean1.sql', df)\n",
    "# save_df_to_excel('debugging', clean_df)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def add_three_features_to_df_based_on_scrabble_word_score():\n",
    "    SCORES = {\n",
    "      'a' : 1, 'b' : 3, 'c' : 3 , 'd' : 2, 'e' : 1, 'f' : 4, 'g' : 2,\n",
    "      'h' : 4, 'i' : 1, 'j' : 8 , 'k' : 5, 'l' : 1, 'm' : 3, 'n' : 1,\n",
    "      'o' : 1, 'p' : 3, 'q' : 10, 'r' : 1, 's' : 1, 't' : 1, 'u' : 1,\n",
    "      'v' : 4, 'w' : 4, 'x' : 8 , 'y' : 4, 'z' : 10,\n",
    "    }\n",
    "    first_letter_of_last_name_scrabble_score = []\n",
    "    last_name_scrabble_score = []\n",
    "    avg_scrabble_letter_score_in_last_name = []\n",
    "    for index, row in clean_df.iterrows():\n",
    "        total_score = 0\n",
    "        word_length = 0\n",
    "        for letter in row['last_name']:\n",
    "            letter_score = SCORES.get(letter.lower(),0)\n",
    "            if total_score == 0:\n",
    "                first_letter_of_last_name_scrabble_score.append(letter_score)\n",
    "            if letter_score != 0:\n",
    "                word_length = word_length + 1\n",
    "            total_score = total_score + letter_score\n",
    "        \n",
    "        if word_length == 0:\n",
    "            avg_scrabble_letter_score_in_last_name.append(0)\n",
    "        else:\n",
    "            avg_scrabble_letter_score_in_last_name.append(total_score / word_length)\n",
    "        \n",
    "        last_name_scrabble_score.append(total_score)\n",
    "    \n",
    "    clean_df['first_letter_of_last_name_scrabble_score'] = first_letter_of_last_name_scrabble_score\n",
    "    clean_df['last_name_scrabble_score'] = last_name_scrabble_score\n",
    "    clean_df['avg_scrabble_letter_score_in_last_name'] = avg_scrabble_letter_score_in_last_name\n",
    "        \n",
    "        \n",
    "#         variable = re.match('.*([A-Za-z]).*', str(row['Ticket']))\n",
    "#         if variable == None:\n",
    "#             has_letter_in_ticket.append(0)\n",
    "#         else:\n",
    "#             has_letter_in_ticket.append(1)\n",
    "#     df['has_letter_in_ticket'] = has_letter_in_ticket\n",
    "    \n",
    "        \n",
    "add_three_features_to_df_based_on_scrabble_word_score()\n",
    "clean_df = clean_df.drop(['last_name'], axis=1)\n",
    "save_df_to_excel('debugging', clean_df)\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterjmyers/anaconda/envs/root3/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/Users/peterjmyers/anaconda/envs/root3/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "Optimization Progress: 100%|██████████| 200/200 [01:24<00:00,  1.70pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8233156689401779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 300/300 [02:26<00:00,  1.48pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.8233156689401779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 400/400 [03:59<00:00,  1.27pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.8278602808846328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 500/500 [05:12<00:00,  3.13pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.8278602808846328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 600/600 [09:00<00:00,  2.97s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.8278602808846328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 700/700 [11:54<00:00,  1.60pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 6 - Current best internal CV score: 0.8278604471377449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 800/800 [13:27<00:00,  1.05pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 7 - Current best internal CV score: 0.8278604471377449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 900/900 [15:27<00:00,  1.60pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 8 - Current best internal CV score: 0.8308565775965618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1000/1000 [17:30<00:00,  1.19s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 9 - Current best internal CV score: 0.8308565775965618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1100/1100 [19:25<00:00,  1.04pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 10 - Current best internal CV score: 0.8308786892604646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1200/1200 [21:51<00:00,  1.33pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 11 - Current best internal CV score: 0.8308786892604646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1300/1300 [24:18<00:00,  1.10s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 12 - Current best internal CV score: 0.8308786892604646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1400/1400 [27:02<00:00,  1.43s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 13 - Current best internal CV score: 0.8308786892604646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1500/1500 [30:27<00:00,  1.24s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 14 - Current best internal CV score: 0.8338640963935544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1600/1600 [33:11<00:00,  1.21pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 15 - Current best internal CV score: 0.8338640963935544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1700/1700 [35:26<00:00,  1.72s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 16 - Current best internal CV score: 0.8338640963935544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1800/1800 [38:03<00:00,  1.07s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 17 - Current best internal CV score: 0.8338640963935544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40.030132683333335 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(DecisionTreeClassifier(input_matrix, criterion=entropy, max_depth=1, min_samples_leaf=19, min_samples_split=18), bootstrap=False, criterion=gini, max_features=1.0, min_samples_leaf=1, min_samples_split=8, n_estimators=100)\n",
      "0.807174887892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_df.drop(['Survived'], axis=1),\n",
    "                                                    clean_df['Survived'], train_size=0.75, test_size=0.25)\n",
    "# print(X_train, X_test, y_train, y_test)\n",
    "\n",
    "tpot = TPOTClassifier(max_time_mins=40, population_size=100, max_eval_time_mins=5, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tpot.builtins import StackingEstimator\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "clean_df = clean_df.drop(['PassengerId'], axis=1)\n",
    "features = clean_df.drop('Survived', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, clean_df['Survived'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:0.8338640963935544\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(criterion=\"entropy\", max_depth=1, min_samples_leaf=19, min_samples_split=18)),\n",
    "    ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=1.0, min_samples_leaf=1, min_samples_split=8, n_estimators=100)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "# test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[112,  22],\n",
       "       [ 23,  66]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(sum(results))\n",
    "confusion_matrix(testing_target, results)\n",
    "\n",
    "# training_features, , training_target, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/peterjmyers/Documents/Python_Modules\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "import numpy as np\n",
    "from file_util.file_util import *\n",
    "from sql_util.sql_util import *\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tpot.builtins import StackingEstimator\n",
    "\n",
    "df = pd.read_csv('./test.csv')\n",
    "\n",
    "\n",
    "Survived = [0] * len(df)\n",
    "df['Survived'] = Survived\n",
    "add_has_letter_in_ticket_to_df()    \n",
    "\n",
    "clean_df = get_df_from_local_query('./sql/clean1.sql', df)\n",
    "add_three_features_to_df_based_on_scrabble_word_score()\n",
    "clean_df = clean_df.drop(['last_name'], axis=1)\n",
    "clean_df = clean_df.drop(['Survived'], axis=1)\n",
    "\n",
    "predict_df = clean_df.drop(['PassengerId'], axis=1)\n",
    "\n",
    "save_df_to_excel('debugging2', clean_df)\n",
    "\n",
    "results = exported_pipeline.predict(predict_df.values)\n",
    "\n",
    "#clean_df.describe()\n",
    "#print(\"Done\")\n",
    "#clean_df.head()\n",
    "# test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "submit_df = clean_df['PassengerId']\n",
    "\n",
    "print(type(submit_df))\n",
    "print(type(results))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "submit_df = pd.concat([submit_df, results_df], axis=1)\n",
    "\n",
    "submit_df.to_csv('./submit.csv')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_excel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-76bbb086b5d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_df_to_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'debugging'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Python_Modules/sql_util/sql_util.py\u001b[0m in \u001b[0;36msave_df_to_excel\u001b[0;34m(filename, *data_frames)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_frame\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdata_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sheet'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_excel'"
     ]
    }
   ],
   "source": [
    "save_df_to_excel('debugging', testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "(223, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy.ndarray\n",
    "print(testing_features.dtype)\n",
    "print(testing_features.shape)\n",
    "np.isnan(testing_features)\n",
    "np.where(np.isnan(testing_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "(418, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(clean_df.values.dtype)\n",
    "print(clean_df.values.shape)\n",
    "np.isnan(clean_df.values)\n",
    "np.where(np.isnan(clean_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-d0ecd1700f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./debug3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "file = open(\"./debug3\",\"w\")\n",
    "line = file.write(testing_features)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
